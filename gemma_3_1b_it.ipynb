{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/uni311/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-3-1b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=device)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_cleaned.csv\")\n",
    "df = pd.read_csv(\"gold_labeled_dataset_1.csv\", sep=\";\")\n",
    "df = df.rename(columns={\"Sentence\": \"source\", \"Traductions\": \"target\"})\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.1, shuffle=True, seed=41)\n",
    "\n",
    "\n",
    "# row = df.iloc[12] # from 10 ahead to avoid using sentences given as examples \n",
    "\n",
    "# author = row[\"Author\"]\n",
    "# date = row[\"Date\"]\n",
    "# region = row[\"Region\"]\n",
    "# sentence = row[\"Sentence\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NON IN-CONTEXT LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Sei un esperto di lingua italiana. Il tuo compito è modernizzare testi antichi in italiano contemporaneo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "\tItaliano Arcaico -> l'armi et insieme con loro passaseno tra li nimici, perçò se alcuno non avesse ardire de questo et sì avevano questo animo.\n",
      "\tItaliano moderno -> L'esercito, insieme a loro, passava tra i nemici, e si chiedevano se nessuno avesse un'idea di questo gruppo, perché avevano questo animo.\n",
      "\tGOLD LABEL       -> Le armi, insieme a loro, passarono tra i nemici; infatti, se qualcuno non avesse avuto coraggio, loro ce l’avevano.\n",
      "-----------------------------------------\n",
      "Sentence 2\n",
      "\tItaliano Arcaico -> Gli uomini spessamente a stare fermi nella bugia incontra la verità.\n",
      "\tItaliano moderno -> “Essere fermi nella bugia porta alla scoperta della verità.”\n",
      "\n",
      "\tGOLD LABEL       -> Gli uomini spesso, per restare fermi nella menzogna, si oppongono alla verità.\n",
      "-----------------------------------------\n",
      "Sentence 3\n",
      "\tItaliano Arcaico -> e l' acconciamento a fare grandissime cose, cioè a ttenere pace et amare Idio e 'l proximo, a ffare cittadi, castella e magioni\n"
     ]
    }
   ],
   "source": [
    "# output = pipe(messages, max_new_tokens=300)\n",
    "# assistant_reply = output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": system_prompt},\n",
    "#     {\"role\": \"user\", \"content\": user_prompt}\n",
    "# ]\n",
    "\n",
    "# print(\"Frase antica:\")\n",
    "# print(sentence)\n",
    "# print(\"Traduzione moderna:\")\n",
    "# print(assistant_reply)\n",
    "\n",
    "\n",
    "i = 1\n",
    "for sample in dataset[\"test\"]:\n",
    "\n",
    "\n",
    "    input_sentence = sample[\"source\"]\n",
    "    target_sentence = sample[\"target\"]\n",
    "\n",
    "    author = sample[\"Author\"]\n",
    "    date = sample[\"Date\"]\n",
    "    region = sample[\"Region\"]\n",
    "\n",
    "\n",
    "    print(f\"Sentence {i}\")\n",
    "    print(f\"\\tItaliano Arcaico -> {input_sentence}\")\n",
    "    \n",
    "    user_prompt = f\"Modernizza il seguente testo antico in italiano contemporaneo:\\n\\n\\\"{input_sentence}\\\"\\n\\n scrivi solo ed esclusivamente la traduzione\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    output = pipe(messages, max_new_tokens=300)\n",
    "    translation = output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "    print(f\"\\tItaliano moderno -> {translation}\")\n",
    "    print(f\"\\tGOLD LABEL       -> {target_sentence}\")\n",
    "\n",
    "    print(f\"-----------------------------------------\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN-CONTEXT LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" Sei un esperto di lingua italiana. Il tuo compito è modernizzare testi antichi in italiano contemporaneo. Di seguito alcuni esempi:\n",
    "\n",
    "Testo antico: \"quella guerra ben fatta l' opera perché etc. Et dall' altra parte Aiaces era uno cavaliere franco e prode all' arme, di gran guisa, ma non era pieno di grande senno\"\n",
    "Traduzione moderna: \"Quella guerra fu ben condotta per raggiungere il suo scopo. Dall'altra parte, Aiace era un cavaliere leale e valoroso nelle armi, di grande statura, ma non molto saggio.\"\n",
    "\n",
    "Testo antico: \"crudele, e di tutte le colpe pigli vendetta, come dice la legge, ed a neuno cavaliere perdoni che pecchi.\"\n",
    "Traduzione moderna: \"È crudele e si vendica di ogni colpa, come stabilisce la legge, e non perdona alcun cavaliere che sbagli.\"\n",
    "\n",
    "Testo antico: \"Non d' altra forza d' animo fue ornato Ponzio Aufidiano, romano cavaliere.\"\n",
    "Traduzione moderna: \"Ponzio Aufidiano, cavaliere romano, non era dotato di maggiore coraggio.\"\n",
    "\n",
    "Testo antico: \"Se questo piace a tutti e se 'l tempo hae bisogno d'avere Pompeio per cavaliere e non per compagno, non riterrò più i fati.\"\n",
    "Traduzione moderna: \"Se questo è il volere di tutti, e se i tempi richiedono Pompeo come guida e non come alleato, allora non tratterrò più il destino.\"\n",
    "\n",
    "Testo antico: \"Officio di questa arte pare che sia dicere appostatamente per fare credere, fine è far credere per lo dire.\"\n",
    "Traduzione moderna: \"Il compito di quest'arte sembra essere quello di parlare con astuzia per far credere; lo scopo è dunque persuadere attraverso il linguaggio.\"\n",
    "\n",
    "Testo antico: \"Ecco e larghi ventipiovoli caggiono delle risolute nebbie; e potresti credere che tutto il cielo cadesse nel mare\"\n",
    "Traduzione moderna: \"Ecco che ampie piogge ventose cadono dalle nebbie diradate; potresti pensare che tutto il cielo stia precipitando nel mare.\"\n",
    "\n",
    "Testo antico: \"Però che or chi spererebbe quello che eziandio questi che non vogliono ancora credere in Cristo, già veggiono con noi, e perché nol possono negare, stridono colli denti.\"\n",
    "Traduzione moderna: \"Chi ormai oserebbe sperare ciò che persino quelli che ancora non vogliono credere in Cristo vedono con i propri occhi insieme a noi, e poiché non possono negarlo, digrignano i denti.\"\n",
    "\n",
    "Testo antico: \"I vendimenti de' morti et le presure de' vivi fece la frode d'uno feroce re.\"\n",
    "Traduzione moderna: \"Fu l'inganno di un re feroce a provocare le vendette dei morti e le catture dei vivi.\"\n",
    "\n",
    "Testo antico: \"Acciocché quegli, il quale ora per le sue gran reità è feroce e onorevole, egli d'ogni male afflitto e tormentato della impietà verso il mio padre.\"\n",
    "Traduzione moderna: \"Affinché colui che ora, per i suoi grandi misfatti, è temuto e rispettato, sia tormentato da ogni male a causa della sua empietà verso mio padre.\"\n",
    "\n",
    "Testo antico: \"Gli uomini spessamente a stare fermi nella bugia incontra la verità.\"\n",
    "Traduzione moderna: \"Gli uomini spesso restano fermi nella menzogna, opponendosi alla verità.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase antica:\n",
      "Corbio nipote d' Ortensio menò sua vita più bassa e più viziosa\n",
      "Traduzione moderna:\n",
      "“Corbio, nipote di Ortensio, morì più velocemente e con una vita più sgradevole.”\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for sample in dataset[\"test\"]:\n",
    "\n",
    "\n",
    "    input_sentence = sample[\"source\"]\n",
    "    target_sentence = sample[\"target\"]\n",
    "\n",
    "    author = sample[\"Author\"]\n",
    "    date = sample[\"Date\"]\n",
    "    region = sample[\"Region\"]\n",
    "\n",
    "\n",
    "    print(f\"Sentence {i}\")\n",
    "    print(f\"\\tItaliano Arcaico -> {input_sentence}\")\n",
    "    \n",
    "    user_prompt = f\"\"\"Modernizza il seguente testo antico in italiano contemporaneo.\n",
    "    Contesto: Autore: {author}, Data: {date}, Regione: {region}\n",
    "    Testo antico: \"{input_sentence}\"\n",
    "\n",
    "    Scrivi solo ed esclusivamente la traduzione moderna:\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    output = pipe(messages, max_new_tokens=300)\n",
    "    translation = output[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "    print(f\"\\tItaliano moderno -> {translation}\")\n",
    "    print(f\"\\tGOLD LABEL       -> {target_sentence}\")\n",
    "\n",
    "    print(f\"-----------------------------------------\")\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
